我想开发一个RAG评测网站，现在需要输出高保真的原型图，请通过以下方式帮我完成所有界面的原型设计，并确保这些原型界面可以直接用于开发： 
1、用户体验分析：先分析这个 网页 的主要功能和用户需求，确定核心交互逻辑。 
2、产品界面规划：作为产品经理，定义关键界面，确保信息架构合理。主界面的颜色搭配方案要控制在一个屏幕内，方便截图分享到社交网络。 
3、高保真 UI 设计：作为 UI 设计师，设计贴近真实 网页 设计规范的界面，使用现代化的 UI 元素，使其具有良好的视觉体验。 
4、HTML 原型实现：使用 HTML + Tailwind CSS（或 Bootstrap）生成所有原型界面，并使用 FontAwesome（或其他开源 UI 组件）让界面更加精美、接近真实的 App 设计。拆分代码文件，保持结构清晰： 
5、每个界面应作为独立的 HTML 文件存放，例如 home.html、profile.html、settings.html 等。

index.html 作为主入口，不直接写入所有界面的 HTML 代码，而是使用 iframe 的方式嵌入这些 HTML 片段，并将所有页面直接平铺展示在 index 页面中，而不是跳转链接。 使用真实的 UI 图片，而非占位符图片（可从 Unsplash、Pexels、Apple 等官方 UI 资源中选择）。请按照以上要求生成完整的 HTML 代码，并确保其可用于实际开发。

功能设计文档为：


# RAG评测网站产品需求文档(PRD)

## 1. 主题

RAG系统评测平台 - 一个简化RAG系统准确率评估流程的综合解决方案

## 2. 介绍

检索增强生成(RAG)技术正迅速成为AI应用的关键基础设施，但目前市场缺乏高效、用户友好的RAG评测工具。本产品旨在开发一个直观的web平台，使用户能够轻松评估其RAG系统的准确率，同时解决数据收集和准备过程中的关键痛点。

## 3. 问题陈述

当前RAG系统评测面临以下主要挑战：

数据准备繁琐：用户需手动创建包含问题、黄金标准答案和系统实际回答的数据集，这一过程耗时且易出错

评估标准不一致：缺乏统一的标准来评判RAG回答的准确性和相关性

测试覆盖不完整：难以创建足够多样化的测试案例以全面评估RAG系统

结果分析困难：缺乏有效工具分析评测结果并提供具体改进建议

## 4. 目标和目的

开发一个易于使用的web平台，简化RAG系统评测流程

提供多种方式简化测试数据的收集和准备

实现自动化评测流程，减少手动工作量

提供详细的评测报告和具体的改进建议

支持不同领域和场景的RAG系统评测需求

## 5. 用户故事

### 数据科学家/AI工程师

"作为数据科学家，我希望能够快速评估我们RAG系统的准确率，而不必花费大量时间准备测试数据"

"我需要了解我的RAG系统在哪些类型的问题上表现较差，以便有针对性地改进"

### 产品经理

"作为产品经理，我希望获得可视化的RAG性能报告，以便向非技术人员解释系统效果"

"我需要追踪RAG系统随时间的性能变化，确保产品迭代改进而非倒退"

### 领域专家

"作为医疗领域专家，我希望能够贡献专业知识评估RAG系统的回答，而不需要具备技术背景"

"我希望平台能支持特定领域的评估标准和术语"

## 6. 功能规格

### 核心功能

#### 基于知识库的自动问答对生成
大模型引导式生成
方法描述：使用大模型（如GPT-4、Claude）分析知识库文件，自动生成相关问题和标准答案
实现方式：
将知识库文档分块输入给大模型，指导它生成该内容相关的问题和权威答案
引导模型生成不同难度和类型的问题（事实性、推理性、应用性等）
设置提示模板："基于以下内容，生成10个问答对，确保答案完全基于文本内容"
优势：完全自动化，节省人力；可快速生成大量测试数据
局限性：模型可能生成的问题过于简单或直接；需要人工审核确保质量
（或者是分成两个任务完成，一个是生成问题，一个是回答问题）

#### 数据收集与准备助手

Excel/CSV导入导出：支持标准格式文件导入导出，兼容现有工作流

#### 自动评测引擎

多模型评测：集成多种大模型(如GPT-4、Claude)进行评分

多维度评估：从准确性、相关性、完整性等多个维度进行评分

定制化评分标准：允许用户根据特定需求调整评分权重和标准

对比评测：支持多个RAG系统或迭代版本的横向对比

#### 人工评测引擎

人工评测引擎作为自动评测的补充，提供更灵活、更专业的评测能力，特别适用于需要深度理解和专业判断的复杂场景。

**多维度评测方式**
- **准确性评估**：
  - 二元判断：标记回答为"正确"或"错误"
  - 细粒度评分：1-5分准确性评分，明确每个分数的评判标准
  - 部分正确标记：允许标记回答中正确和错误的部分
  
- **质量维度评估**：
  - 相关性评分：回答与问题的相关程度（1-5分）
  - 完整性评分：回答是否涵盖了问题的所有方面（1-5分）
  - 简洁性评分：回答是否简明扼要不含冗余信息（1-5分）
  
- **专业领域评估**：
  - 专业准确性：由领域专家评判专业知识的准确性
  - 术语使用：专业术语使用的准确性和适当性
  - 引用质量：对知识库内容引用的准确性和恰当性

**评测工作流**
- **批量评测模式**：
  - 列表视图展示多个问答对，支持快速评分
  - 一键应用相同评分标准到类似问题
  - 进度跟踪和断点续评
  
- **深度评测模式**：
  - 单个问答对详细评测界面
  - 并排显示问题、标准答案、RAG回答
  - 支持对回答中特定段落添加注释和评分
  - 知识库原文引用查看，核实回答来源

**协作评测功能**
- 多评测人分配与管理
- 评测结果一致性检查
- 争议问题标记与讨论功能
- 评测人绩效与可靠性分析

**评测辅助工具**
- 高亮工具：标记回答中的关键信息、错误或缺失部分
- 对比工具：并排比较多个RAG系统对同一问题的回答
- 知识库引用工具：便捷查询和引用原始知识库内容
- 评测模板：根据不同领域和场景快速应用预设评测标准

**集成与数据利用**
- 人工评测数据用于训练和改进自动评测模型
- 历史评测结果分析，识别常见错误模式
- 人工评测与自动评测结果对比分析
- 支持导出评测结果和详细注释

**用户体验设计**
- 直观的评测界面，减少评测人认知负担
- 键盘快捷键支持，提高评测效率
- 自定义评测视图和工作流
- 评测人只能看到评测的页面，不能看到其他页面，需要提供评测页面分析的功能

人工评测引擎与自动评测引擎相互补充，共同提供全面、可靠的RAG系统评测能力，既满足高效率评测需求，也确保复杂场景下的评测质量。

#### 分析与报告

可视化仪表盘：直观展示评测结果和关键指标

错误分析：自动识别RAG系统常见错误模式和类型

改进建议：基于评测结果提供具体可行的改进方向

历史趋势：追踪RAG系统性能随时间的变化

### 高级功能

自动测试生成：基于已有数据自动生成更多测试案例

协作功能：支持团队协作评审和批注

API接口：提供编程接口，方便集成到现有开发流程

## 7. 技术要求

1. 前端：React框架构建的响应式Web界面

2. 后端：Python基础架构，支持分布式处理大量评测任务

3. 数据库：Mysql

数据加密传输和存储

访问控制和用户认证

敏感信息过滤机制

## 8. 好处

效率提升：减少80%的评测数据准备时间

决策支持：提供数据驱动的RAG系统改进方向

质量保证：实现RAG系统质量的标准化评估

成本节约：减少手动评测的人力成本和出错风险

可追溯性：完整记录RAG系统性能演变历史

## 9. 关键绩效指标(KPI)

1. 用户采用率：平台活跃用户数和增长率

效率指标：

评测数据准备时间减少百分比

自动化评测流程完成时间

3. 质量指标：

评测结果一致性(不同模型间评分差异)

用户对评测结果的满意度

业务指标：

订阅用户留存率

每用户平均收入(ARPU)

平台使用频率

## 10. 开发风险

技术风险：

大模型评测标准可能随时间变化

对不同领域RAG系统的通用评测挑战

API依赖和成本控制

用户风险：

用户可能对自动评测结果持怀疑态度

数据隐私和安全担忧

市场风险：

大型AI提供商可能推出类似工具

评测标准缺乏行业共识

## 11. 缓解策略

技术风险缓解：

模块化设计，便于更新评测模型

支持用户自定义评测标准

提供多种评测方法供选择

用户风险缓解：

提供评测结果解释和证据

实施严格的数据安全措施

支持本地部署选项

3. 市场风险缓解：

专注特定行业垂直领域的定制化评测

积极参与开源评测标准制定

## 12. 结论

RAG评测平台旨在解决当前RAG系统评估过程中的关键痛点，特别是数据收集和准备的困难。通过提供自动化工具、多维度评估和详细分析，本产品将显著提高RAG系统评测的效率和质量。该平台不仅满足了技术用户的需求，也为产品经理和领域专家提供了易用的评测工具。

随着RAG技术在各行业的广泛应用，一个专业的评测平台将成为确保AI系统质量和可靠性的关键工具。我们相信，通过持续迭代和用户反馈，该平台将成为RAG开发生态系统中不可或缺的组成部分。


## 实施路线图

第一阶段 (3个月)

核心数据导入功能

基础评测引擎

简单报告功能

第二阶段 (3个月)

高级数据收集工具

多维度评测系统

详细分析报告

第三阶段 (6个月)

协作功能

API和集成

行业特定解决方案